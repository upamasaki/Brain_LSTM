{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "mylstm_v3.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "NOipl-bwC6qn",
        "tbphTogkC6qn",
        "BxoMkJnhC6qo",
        "FRI1N8OzC6qo",
        "dKl0GC0CC6qp",
        "1TCAfXG8C6qq",
        "OLSUiP9MC6qq",
        "AS_4zQysC6qr",
        "FqozURwfC6qs",
        "nHyWsW5JC6qs"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/upamasaki/Brain_LSTM/blob/main/mylstm_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkRnUZn5C6qb"
      },
      "source": [
        "\n",
        "\n",
        "# ライブラリ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:26:38.669413Z",
          "iopub.execute_input": "2021-10-24T14:26:38.670407Z",
          "iopub.status.idle": "2021-10-24T14:26:46.383241Z",
          "shell.execute_reply.started": "2021-10-24T14:26:38.670292Z",
          "shell.execute_reply": "2021-10-24T14:26:46.382541Z"
        },
        "trusted": true,
        "id": "wRrN7RU4C6qf"
      },
      "source": [
        "#!pip install joypy\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pprint\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "#from joypy import joyplot for matplotlib\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "#import optuna\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.preprocessing import RobustScaler, normalize, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GroupKFold, KFold\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "#%matplotlib inline\n",
        "%matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtWfgzRHEHC4"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:26:46.385117Z",
          "iopub.execute_input": "2021-10-24T14:26:46.385416Z",
          "iopub.status.idle": "2021-10-24T14:26:48.217744Z",
          "shell.execute_reply.started": "2021-10-24T14:26:46.385382Z",
          "shell.execute_reply": "2021-10-24T14:26:48.216704Z"
        },
        "trusted": true,
        "id": "0bsCjUzPC6qh"
      },
      "source": [
        "if tf.device('/CPU:0'):\n",
        "    print(tf.device('/CPU:0'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hQA940dC6qi"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:26:48.219219Z",
          "iopub.execute_input": "2021-10-24T14:26:48.219613Z",
          "iopub.status.idle": "2021-10-24T14:26:48.232787Z",
          "shell.execute_reply.started": "2021-10-24T14:26:48.219570Z",
          "shell.execute_reply": "2021-10-24T14:26:48.231935Z"
        },
        "trusted": true,
        "id": "3hqQe3d1C6qi"
      },
      "source": [
        "# When Debug mode is true, this notebook use small train data.\n",
        "debug_mode = False\n",
        "debug_data_count = int(1000)\n",
        "\n",
        "file_override = False\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "# folloiwng settig takes time due to plotly is so slow.\n",
        "visualize = False  # [True | False]\n",
        "visualize2 = False\n",
        "visualize3 = False\n",
        "\n",
        "# Use trained model. no run training. Just use trained model only.\n",
        "\n",
        "use_trained_model = False\n",
        "\n",
        "###################################################\n",
        "# Path setting\n",
        "#\n",
        "google_mount_path   = '/content/drive'\n",
        "google_PROJECT_dir  = 'MyDrive/2021/100_GoogleBrain_VentilatorPressurePrediction'\n",
        "root_path           = '{}/{}'.format(google_mount_path, google_PROJECT_dir)\n",
        "path                = '{}/{}'.format(root_path, 'datasets')\n",
        "dataset_ver         = 'v3.1'\n",
        "exp_name            = 'mylstm_v3.3_lite'\n",
        "dataset_path        = '{}/{}/{}'.format(root_path, 'datasets', dataset_ver)\n",
        "log_path            = '{}/{}/{}'.format(root_path, 'log', exp_name)\n",
        "result_path         = '{}/{}/{}/{}'.format(root_path, 'log', exp_name, 'result')\n",
        "\n",
        "\n",
        "###################################################\n",
        "# Google Drive Setting\n",
        "#\n",
        "if(not os.path.exists(google_mount_path)):\n",
        "  from google.colab import drive\n",
        "  drive.mount(google_mount_path)\n",
        "\n",
        "###################################################\n",
        "# Make dir\n",
        "#\n",
        "os.makedirs(log_path, exist_ok=True)\n",
        "os.makedirs(dataset_path, exist_ok=True)\n",
        "os.makedirs(result_path, exist_ok=True)\n",
        "\n",
        "\n",
        "# /content/drive/MyDrive/2021/100_GoogleBrain_VentilatorPressurePrediction/datasets\n",
        "#log_path = '/content/drive/MyDrive/2021/100_GoogleBrain_VentilatorPressurePrediction/log'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aNKpWXLazSa"
      },
      "source": [
        "#os.path.exists(google_mount_path)\n",
        "#from google.colab import drive\n",
        "#drive.mount(google_mount_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz9wDIJnbgxL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDAvlqnuC6qj"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:26:48.235424Z",
          "iopub.execute_input": "2021-10-24T14:26:48.235987Z",
          "iopub.status.idle": "2021-10-24T14:27:06.192388Z",
          "shell.execute_reply.started": "2021-10-24T14:26:48.235945Z",
          "shell.execute_reply": "2021-10-24T14:27:06.191591Z"
        },
        "trusted": true,
        "id": "24-u1LMzC6qj"
      },
      "source": [
        "\n",
        "if(file_override):\n",
        "  train = pd.read_csv(f\"{path}/train.csv\")\n",
        "  test = pd.read_csv(f\"{path}/test.csv\")\n",
        "  submission = pd.read_csv(f'{path}/sample_submission.csv')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvT1IKmmDNb8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKt-ORRpC6qk"
      },
      "source": [
        "# confirm linearity of time_step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.196482Z",
          "iopub.execute_input": "2021-10-24T14:27:06.196688Z",
          "iopub.status.idle": "2021-10-24T14:27:06.202838Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.196663Z",
          "shell.execute_reply": "2021-10-24T14:27:06.202063Z"
        },
        "trusted": true,
        "id": "KWY3w_RKC6qk"
      },
      "source": [
        "if visualize:\n",
        "    time_step_diff_limit = 0.04\n",
        "    non_liner_timestep_breath_ids = list()\n",
        "    for k, grp in tqdm(train.groupby(\"breath_id\")):\n",
        "        diff_se = grp[\"time_step\"].diff()\n",
        "        diff_chk = diff_se[diff_se > time_step_diff_limit]\n",
        "        if len(diff_chk) != 0:\n",
        "            non_liner_timestep_breath_ids.append(k)\n",
        "#\n",
        "#print(non_liner_timestep_breath_ids)\n",
        "## results are following:\n",
        "## [803, 2327, 3178, 4199, 5830, 10277, 11502, 13238, 15803, 16315, 16634, 18117, 18600, 24127, 25397, 28189, 28942, 30181, 32296, 36128, 36175, 37711, 38237, 38415, 39045, 39722, 42317, 42988, 43344, 44245, 45197, 46324, 49849, 53877, 54129, 55244, 55851, 61454, 64662, 67422, 67748, 72104, 74766, 76037, 78768, 79105, 80375, 87127, 87776, 89084, 91883, 93186, 98677, 102063, 104001, 106034, 107067, 109693, 111439, 112027, 115588, 119689, 120878, 121135, 125136]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ustQW9UTC6ql"
      },
      "source": [
        "# visualize non linearity time_step (直線でないtime_stepの可視化)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.204164Z",
          "iopub.execute_input": "2021-10-24T14:27:06.204689Z",
          "iopub.status.idle": "2021-10-24T14:27:06.216114Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.204650Z",
          "shell.execute_reply": "2021-10-24T14:27:06.215297Z"
        },
        "trusted": true,
        "id": "3A05dCyYC6ql"
      },
      "source": [
        "if visualize:\n",
        "    non_liner_timestep_df = train[train[\"breath_id\"].isin(non_liner_timestep_breath_ids)]\n",
        "    fig = go.Figure()\n",
        "    for k,grp in non_liner_timestep_df.groupby(\"breath_id\"):\n",
        "        grp = grp.reset_index(drop=True)\n",
        "        fig.add_trace(go.Scatter(x=grp.index, y=grp[\"time_step\"], mode='lines', name=k))\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hZdpoPjC6qm"
      },
      "source": [
        "# visualize linearity time_step (直線なtime_stepの可視化)\n",
        "\n",
        "おっと、傾きが色々とある！\n",
        "計測機器側の計測インターバルがずれるとは思えないので、一回のサイクルを80分割したのだと思う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.219192Z",
          "iopub.execute_input": "2021-10-24T14:27:06.219489Z",
          "iopub.status.idle": "2021-10-24T14:27:06.225804Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.219462Z",
          "shell.execute_reply": "2021-10-24T14:27:06.225073Z"
        },
        "trusted": true,
        "id": "O31gC3DFC6qm"
      },
      "source": [
        "if visualize:\n",
        "    liner_timestep_df = train[~train[\"breath_id\"].isin(non_liner_timestep_breath_ids)]\n",
        "    fig = go.Figure()\n",
        "    for k,grp in tqdm(liner_timestep_df[:80*10000].groupby(\"breath_id\")):\n",
        "        grp = grp.reset_index(drop=True)\n",
        "        fig.add_trace(go.Scatter(x=grp.index, y=grp[\"time_step\"], mode='lines', name=k))\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOipl-bwC6qn"
      },
      "source": [
        "# find minus pressure data (ターゲット値ですが)にマイナス値を持つデータを探す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.227550Z",
          "iopub.execute_input": "2021-10-24T14:27:06.228111Z",
          "iopub.status.idle": "2021-10-24T14:27:06.236059Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.228074Z",
          "shell.execute_reply": "2021-10-24T14:27:06.235242Z"
        },
        "trusted": true,
        "id": "VaI-KKdhC6qn"
      },
      "source": [
        "if visualize:\n",
        "    minus_pressure_breath_ids = list()\n",
        "    for k, grp in tqdm(train.groupby(\"breath_id\")):\n",
        "        m = grp[\"pressure\"].min()\n",
        "        if m < 0:\n",
        "            minus_pressure_breath_ids.append(k)\n",
        "# print(minus_pressure_breath_ids)\n",
        "# [542, 851, 3928, 7949, 11216, 13594, 16599, 19236, 20075, 22164, 23710, 27195, 27731, 30127, 36474, 40431, 40753, 43103, 43630, 44309, 45099, 45681, 45877, 46018, 46020, 46486, 47325, 49376, 49941, 50459, 52137, 53057, 54206, 56152, 56760, 57119, 58835, 59101, 60949, 65596, 67080, 67788, 70753, 71461, 72011, 74977, 77803, 83713, 85391, 86508, 90584, 91132, 91464, 92955, 94037, 97520, 98041, 98080, 101951, 106703, 108406, 109424, 109761, 110499, 111419, 112036, 113323, 113639, 118131, 119582, 120445, 121570, 124575]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbphTogkC6qn"
      },
      "source": [
        "# visualize minus pressure data (負のpressureを持つデータを可視化)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.237740Z",
          "iopub.execute_input": "2021-10-24T14:27:06.238076Z",
          "iopub.status.idle": "2021-10-24T14:27:06.250285Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.238041Z",
          "shell.execute_reply": "2021-10-24T14:27:06.249505Z"
        },
        "trusted": true,
        "id": "i4GH2fi4C6qo"
      },
      "source": [
        "if visualize:\n",
        "    minus_pressure_df = train[train[\"breath_id\"].isin(minus_pressure_breath_ids)]\n",
        "    minus_pressure_df_plotly = pd.melt(minus_pressure_df,id_vars=[\"time_step\",\"breath_id\"], value_vars=[\"pressure\"])\n",
        "    fig = px.line(minus_pressure_df_plotly, x=\"time_step\" , y=\"value\",color = \"variable\",line_group =\"breath_id\")\n",
        "    for line in fig.data:\n",
        "        line['line']['color']='rgba(0, 0, 255, 0.1)'\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxoMkJnhC6qo"
      },
      "source": [
        "# count steps of u_out = 1   (排気段階)のstep数をtrain/testデータで確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.251815Z",
          "iopub.execute_input": "2021-10-24T14:27:06.252125Z",
          "iopub.status.idle": "2021-10-24T14:27:06.260060Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.252088Z",
          "shell.execute_reply": "2021-10-24T14:27:06.259233Z"
        },
        "trusted": true,
        "id": "0l47j32RC6qo"
      },
      "source": [
        "\n",
        "\n",
        "if visualize3:\n",
        "    u_out_open_step_counts = list()\n",
        "    for k, grp in tqdm(train.groupby(\"breath_id\")):\n",
        "        count = grp.groupby(\"u_out\")[\"id\"].count()[1]\n",
        "        u_out_open_step_counts.append(count)\n",
        "    \n",
        "    u_out_open_step_counts_test = list()\n",
        "    for k, grp in tqdm(test.groupby(\"breath_id\")):\n",
        "        count = grp.groupby(\"u_out\")[\"id\"].count()[1]\n",
        "        u_out_open_step_counts_test.append(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRI1N8OzC6qo"
      },
      "source": [
        "# visualize by histgram counts of u_out = 1 (排気段階)のstep数の分布を可視化\n",
        "48 ~ 51にまとまっている。裾のは、55まで。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.261531Z",
          "iopub.execute_input": "2021-10-24T14:27:06.261840Z",
          "iopub.status.idle": "2021-10-24T14:27:06.269069Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.261804Z",
          "shell.execute_reply": "2021-10-24T14:27:06.268362Z"
        },
        "trusted": true,
        "id": "NSeM7TBwC6qp"
      },
      "source": [
        "if visualize3: \n",
        "    fig = px.histogram(x=u_out_open_step_counts,nbins=8)\n",
        "    fig.update_layout(title=\"u_out = 1 count histgram in train\")\n",
        "    fig.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.270594Z",
          "iopub.execute_input": "2021-10-24T14:27:06.270862Z",
          "iopub.status.idle": "2021-10-24T14:27:06.278678Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.270827Z",
          "shell.execute_reply": "2021-10-24T14:27:06.277905Z"
        },
        "trusted": true,
        "id": "8qkupv-sC6qp"
      },
      "source": [
        "if visualize3:\n",
        "    fig = px.histogram(x=u_out_open_step_counts_test,nbins=8)\n",
        "    fig.update_layout(title=\"u_out = 1 count histgram in test\")\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKl0GC0CC6qp"
      },
      "source": [
        "# data count of counts over 52 of u_out = 1 (排気段階)のstep数が52以上のデータ数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.281635Z",
          "iopub.execute_input": "2021-10-24T14:27:06.281886Z",
          "iopub.status.idle": "2021-10-24T14:27:06.289167Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.281861Z",
          "shell.execute_reply": "2021-10-24T14:27:06.288460Z"
        },
        "trusted": true,
        "id": "vTu3cbhzC6qp"
      },
      "source": [
        "if visualize3: \n",
        "    u_out_open_step_counts_over52 = list()\n",
        "    for k, grp in tqdm(train.groupby(\"breath_id\")):\n",
        "        count = grp.groupby(\"u_out\")[\"id\"].count()[1]\n",
        "        if count > 51:\n",
        "            u_out_open_step_counts_over52.append(count)\n",
        "    len(u_out_open_step_counts_over52)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TCAfXG8C6qq"
      },
      "source": [
        "# visualize pressuer of u_out = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.293791Z",
          "iopub.execute_input": "2021-10-24T14:27:06.294361Z",
          "iopub.status.idle": "2021-10-24T14:27:06.301672Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.294330Z",
          "shell.execute_reply": "2021-10-24T14:27:06.300915Z"
        },
        "trusted": true,
        "id": "h_XPEabOC6qq"
      },
      "source": [
        "if visualize3:\n",
        "    train_visualize3 = train[:80*1000]\n",
        "    train_visualize3 = train_visualize3[train_visualize3[\"u_out\"] == 1]\n",
        "    pressure_df_uout = pd.melt(train_visualize3,id_vars=[\"time_step\",\"breath_id\"], value_vars=[\"pressure\"])\n",
        "    fig = px.line(pressure_df_uout, x=\"time_step\" , y=\"value\",color = \"variable\",line_group =\"breath_id\")\n",
        "    for line in fig.data:\n",
        "        line['line']['color']='rgba(0, 0, 255, 0.05)'\n",
        "    fig.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLSUiP9MC6qq"
      },
      "source": [
        "# count steps of u_out = 0 step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.303780Z",
          "iopub.execute_input": "2021-10-24T14:27:06.304515Z",
          "iopub.status.idle": "2021-10-24T14:27:06.312065Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.304477Z",
          "shell.execute_reply": "2021-10-24T14:27:06.311089Z"
        },
        "trusted": true,
        "id": "4NXA3ovlC6qq"
      },
      "source": [
        "if visualize3:\n",
        "    u_out_close_step_counts = list()\n",
        "    for k, grp in tqdm(train.groupby(\"breath_id\")):\n",
        "        count = grp.groupby(\"u_out\")[\"id\"].count()\n",
        "        #print(\"count : {}\".format(count))\n",
        "        \n",
        "        count = grp.groupby(\"u_out\")[\"id\"].count()[0]\n",
        "        u_out_close_step_counts.append(count)\n",
        "    \n",
        "    u_out_close_step_counts_test = list()\n",
        "    for k, grp in tqdm(test.groupby(\"breath_id\")):\n",
        "        count = grp.groupby(\"u_out\")[\"id\"].count()[0]\n",
        "        u_out_close_step_counts_test.append(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.313523Z",
          "iopub.execute_input": "2021-10-24T14:27:06.314009Z",
          "iopub.status.idle": "2021-10-24T14:27:06.322052Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.313971Z",
          "shell.execute_reply": "2021-10-24T14:27:06.321261Z"
        },
        "trusted": true,
        "id": "Zb2AQG5aC6qq"
      },
      "source": [
        "if visualize3:\n",
        "    u_out_close_step_counts = list()\n",
        "    for k, grp in tqdm(train.groupby(\"breath_id\")):\n",
        "        count = grp.groupby(\"u_out\")[\"id\"].count()#[0]\n",
        "    print(count)\n",
        "        #u_out_close_step_counts.append(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.323837Z",
          "iopub.execute_input": "2021-10-24T14:27:06.324215Z",
          "iopub.status.idle": "2021-10-24T14:27:06.331614Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.324169Z",
          "shell.execute_reply": "2021-10-24T14:27:06.330832Z"
        },
        "trusted": true,
        "id": "S-BAAtIZC6qq"
      },
      "source": [
        "if visualize3: \n",
        "    fig = px.histogram(x=u_out_close_step_counts,nbins=8)\n",
        "    fig.update_layout(title=\"u_out = 0 count histgram in train\")\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.332740Z",
          "iopub.execute_input": "2021-10-24T14:27:06.333416Z",
          "iopub.status.idle": "2021-10-24T14:27:06.340567Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.333378Z",
          "shell.execute_reply": "2021-10-24T14:27:06.339804Z"
        },
        "trusted": true,
        "id": "I0-10QUoC6qr"
      },
      "source": [
        "if visualize3:\n",
        "    fig = px.histogram(x=u_out_close_step_counts_test,nbins=8)\n",
        "    fig.update_layout(title=\"u_out = 0 count histgram in test\")\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KqsSYM_C6qr"
      },
      "source": [
        "# Utilitys\n",
        "\n",
        "data_cleanの中で、直線性の無いデータ、負のpressureを持つデータ、u_out = 1のstep数52以上あるデータを削除。<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.342173Z",
          "iopub.execute_input": "2021-10-24T14:27:06.342450Z",
          "iopub.status.idle": "2021-10-24T14:27:06.362597Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.342416Z",
          "shell.execute_reply": "2021-10-24T14:27:06.361837Z"
        },
        "trusted": true,
        "id": "V7QkQTzYC6qr"
      },
      "source": [
        "def data_clean(df):\n",
        "    ## pickup ignore breath id\n",
        "    ignore_breath_ids = set()\n",
        "    \n",
        "    \n",
        "    time_step_diff_limit = 0.04\n",
        "    for k, grp in tqdm(df.groupby(\"breath_id\")):\n",
        "        \n",
        "        ## ignore non liner time_step data\n",
        "        diff_se = grp[\"time_step\"].diff()\n",
        "        diff_chk = diff_se[diff_se > time_step_diff_limit]\n",
        "        if len(diff_chk) != 0:\n",
        "            ignore_breath_ids.add(k)\n",
        "            \n",
        "        ## ignor negative pressure data\n",
        "        m = grp[\"pressure\"].min()\n",
        "        if m < 0:\n",
        "            ignore_breath_ids.add(k)\n",
        "            \n",
        "        ## ignore (u_out = 0 step) < 29\n",
        "        count0 = grp.groupby(\"u_out\")[\"id\"].count()[0]\n",
        "        if count0 < 29:\n",
        "            ignore_breath_ids.add(k)\n",
        "    \n",
        "        count1 = grp.groupby(\"u_out\")[\"id\"].count()[1]\n",
        "        if count1 > 51:\n",
        "            ignore_breath_ids.add(k)\n",
        "    \n",
        "    df = df[~df[\"breath_id\"].isin(np.array(list(ignore_breath_ids)))]\n",
        "    return df\n",
        "\n",
        "def change_type(df):\n",
        "    #df['R'] = df['R'].astype(str)\n",
        "    #df['C'] = df['C'].astype(str)\n",
        "    return df\n",
        "\n",
        "def str2dumy(df, target_col):\n",
        "    #####################################\n",
        "    # R or C\n",
        "    #\n",
        "    _df = pd.get_dummies(df[target_col])\n",
        "    new_col = []\n",
        "    for col in _df.columns:\n",
        "        new_col.append(\"{}{}\".format(target_col, col))\n",
        "    print(\"new_col:{}\".format(new_col))\n",
        "    _df.columns = new_col\n",
        "    df = pd.concat([df, _df], axis=1)\n",
        "    # df = df.drop([target_col])\n",
        "    df = df.drop(columns=target_col)\n",
        "    return df\n",
        "\n",
        "def add_features(df):\n",
        "    print(\"Rolling......\")\n",
        "    df['u_in_roll10'] = df.groupby('breath_id')['u_in'].rolling(10, min_periods=1).mean().values\n",
        "    df['u_in_roll20'] = df.groupby('breath_id')['u_in'].rolling(20, min_periods=1).mean().values\n",
        "    print(\"...............................ok\")\n",
        "    print(\"Diff......\")\n",
        "    df['u_in_diff1'] = df.groupby('breath_id')['u_in'].diff(1)\n",
        "    df['u_in_diff2'] = df.groupby('breath_id')['u_in'].diff(2)\n",
        "    print(\"...............................ok\")\n",
        "\n",
        "\n",
        "    \n",
        "    print(\"Cumsum, shift......\")\n",
        "    df['area'] = df['time_step'] * df['u_in']\n",
        "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
        "    df['u_in_cumsum'] = df.groupby('breath_id')['u_in'].cumsum()\n",
        "    print(\"...............................ok\")\n",
        "\n",
        "    print(\"Shift......\")\n",
        "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
        "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
        "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
        "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
        "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
        "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
        "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
        "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
        "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
        "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
        "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
        "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
        "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
        "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
        "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
        "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
        "    print(\"...............................ok\")\n",
        "\n",
        "    print(\"IN, MAX......\")\n",
        "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
        "    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n",
        "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
        "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
        "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
        "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
        "    print(\"...............................ok\")\n",
        "\n",
        "    print(\"IN, MAX......\")\n",
        "    df['cross']= df['u_in']*df['u_out']\n",
        "    df['cross2']= df['time_step']*df['u_out']\n",
        "    print(\"...............................ok\")\n",
        "\n",
        "\n",
        "    print(\"Cross......\")\n",
        "    df['cross']= df['u_in']*df['u_out']\n",
        "    df['cross2']= df['time_step']*df['u_out']\n",
        "    print(\"...............................ok\")\n",
        "\n",
        "    print(\"Category......\")\n",
        "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
        "    df = str2dumy(df, 'R__C')\n",
        "    df = str2dumy(df, 'R')\n",
        "    df = str2dumy(df, 'C')\n",
        "    df = str2dumy(df, 'u_out')\n",
        "    print(\"...............................ok\")\n",
        "\n",
        "    df = df.fillna(0)\n",
        "    return df\n",
        "\n",
        "\n",
        "def tf_tpu_or_gpu_or_cpu():\n",
        "    tpu = None\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        print('Running on TPU ', tpu.master())\n",
        "    except ValueError:\n",
        "        tpu = None\n",
        "\n",
        "    if tpu:\n",
        "        tf.config.experimental_connect_to_cluster(tpu)\n",
        "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "        return \"tpu\"\n",
        "\n",
        "    elif tf.test.is_gpu_available():\n",
        "        strategy = tf.distribute.get_strategy()\n",
        "        print('Running on GPU')\n",
        "        return \"gpu\"\n",
        "\n",
        "    else:\n",
        "        strategy = tf.distribute.get_strategy()\n",
        "        print('Running on CPU')\n",
        "        return \"cpu\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS_4zQysC6qr"
      },
      "source": [
        "# 排気時のみのデータ作成\n",
        "\n",
        "u_outのstep数最大(今回は51)でcut。短い場合は、一番最後のデータをコピーして51に合わせる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.365880Z",
          "iopub.execute_input": "2021-10-24T14:27:06.366089Z",
          "iopub.status.idle": "2021-10-24T14:27:06.374034Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.366067Z",
          "shell.execute_reply": "2021-10-24T14:27:06.373328Z"
        },
        "trusted": true,
        "id": "th23Hd7bC6qs"
      },
      "source": [
        "def exhaust_mode_df(df):\n",
        "    grp_len = int(51)\n",
        "    new_df = pd.DataFrame()\n",
        "    for k, grp in df.groupby(\"breath_id\"):\n",
        "        tmp_df = grp[grp[\"u_out\"] == 1]\n",
        "        rowno = tmp_df.shape[0]\n",
        "        for l in range(grp_len - rowno):\n",
        "            tmp_df = tmp_df.append(grp.tail(1),ignore_index=True)\n",
        "        new_df = new_df.append(tmp_df,ignore_index=True)\n",
        "    return new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.376593Z",
          "iopub.execute_input": "2021-10-24T14:27:06.377866Z",
          "iopub.status.idle": "2021-10-24T14:27:06.385907Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.377837Z",
          "shell.execute_reply": "2021-10-24T14:27:06.385177Z"
        },
        "trusted": true,
        "id": "4lkqooqgC6qs"
      },
      "source": [
        "def uout0_mode_df(df):\n",
        "    grp_len = int(32)\n",
        "    new_df = pd.DataFrame()\n",
        "    for k, grp in df.groupby(\"breath_id\"):\n",
        "        tmp_df = grp[grp[\"u_out\"] == 0]\n",
        "        rowno = tmp_df.shape[0]\n",
        "        if \"pressure\" in tmp_df.columns:\n",
        "            for l in range(grp_len - rowno):\n",
        "                tmp_df = tmp_df.append({\"\"},ignore_index=True)\n",
        "        else:\n",
        "            for l in range(grp_len - rowno):\n",
        "                tmp_df = tmp_df.append(grp.tail(1),ignore_index=True)\n",
        "        new_df = new_df.append(tmp_df,ignore_index=True)\n",
        "    return new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqozURwfC6qs"
      },
      "source": [
        "# データ読み込みとconfig設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:06.387543Z",
          "iopub.execute_input": "2021-10-24T14:27:06.388067Z",
          "iopub.status.idle": "2021-10-24T14:27:14.276228Z",
          "shell.execute_reply.started": "2021-10-24T14:27:06.388023Z",
          "shell.execute_reply": "2021-10-24T14:27:14.275462Z"
        },
        "trusted": true,
        "id": "UnOI7wnFC6qs"
      },
      "source": [
        "#path = '/content/drive/MyDrive/2021/100_GoogleBrain_VentilatorPressurePrediction/datasets'\n",
        "train = pd.read_csv(f\"{path}/train.csv\")\n",
        "test = pd.read_csv(f\"{path}/test.csv\")\n",
        "submission = pd.read_csv(f'{path}/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHyWsW5JC6qs"
      },
      "source": [
        "# Debug モード時の処理\n",
        "データ数を削減<br>\n",
        "In use_trained_model case, use new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:14.277403Z",
          "iopub.execute_input": "2021-10-24T14:27:14.277729Z",
          "iopub.status.idle": "2021-10-24T14:27:14.283597Z",
          "shell.execute_reply.started": "2021-10-24T14:27:14.277688Z",
          "shell.execute_reply": "2021-10-24T14:27:14.282948Z"
        },
        "trusted": true,
        "id": "KJ9oS4uWC6qt"
      },
      "source": [
        "if debug_mode:\n",
        "    if use_trained_model:\n",
        "        train = train[80*debug_data_count:80*debug_data_count*2]\n",
        "        test = test[80*debug_data_count:80*debug_data_count*2]\n",
        "    else:\n",
        "        train = train[:80*debug_data_count]\n",
        "        test = test[:80*debug_data_count]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjcUWZaZC6qt"
      },
      "source": [
        "# apply utilitys for data\n",
        "データの追加と削除がメイン"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:27:14.285222Z",
          "iopub.execute_input": "2021-10-24T14:27:14.285773Z",
          "iopub.status.idle": "2021-10-24T14:28:41.057699Z",
          "shell.execute_reply.started": "2021-10-24T14:27:14.285737Z",
          "shell.execute_reply": "2021-10-24T14:28:41.056896Z"
        },
        "trusted": true,
        "id": "sMalnCJ6C6qt"
      },
      "source": [
        "# exhaust_mode_df() do not work collectry\n",
        "u_out1_only = False\n",
        "\n",
        "if(file_override or (not os.path.exists('{}/train_full_feat.csv'.format(dataset_path)))):\n",
        "\n",
        "  ## trainのみ、data_cleanを実施\n",
        "  #\n",
        "  train.to_csv('{}/train_origin.csv'.format(dataset_path))\n",
        "\n",
        "  train = data_clean(train)  ## time_stepがリニア出ないものは削除\n",
        "  train.to_csv('{}/train_clean.csv'.format(dataset_path))\n",
        "\n",
        "\n",
        "  if u_out1_only:\n",
        "      train = exhaust_mode_df(train)\n",
        "\n",
        "  train = add_features(train)\n",
        "  train = change_type(train)\n",
        "  train.to_csv('{}/train_full_feat.csv'.format(dataset_path))\n",
        "\n",
        "  print(train.head(10))\n",
        "\n",
        "if(file_override or (not os.path.exists('{}/test_full_feat.csv'.format(dataset_path)))):\n",
        "  if u_out1_only:\n",
        "      test = exhaust_mode_df(test)\n",
        "  test = add_features(test)\n",
        "  test = change_type(test)\n",
        "  test.to_csv('{}/test_full_feat.csv'.format(dataset_path))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoEoNg0GswXj"
      },
      "source": [
        "if(file_override or (not os.path.exists('{}/sample_submission.csv'.format(dataset_path)))):\n",
        "    submission.to_csv('{}/sample_submission.csv'.format(dataset_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z8iQ1cL9Tvp"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y0dPJPEUiiQ"
      },
      "source": [
        "train = pd.read_csv(f\"{dataset_path}/train_full_feat.csv\")\n",
        "test = pd.read_csv(f\"{dataset_path}/test_full_feat.csv\")\n",
        "submission = pd.read_csv(f'{dataset_path}/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEsiZUjpC6qt"
      },
      "source": [
        "# choose useful data for train and test and create target data\n",
        "targetデータの作成と、不要なcolumnの削除。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:28:41.059043Z",
          "iopub.execute_input": "2021-10-24T14:28:41.059318Z",
          "iopub.status.idle": "2021-10-24T14:28:41.411586Z",
          "shell.execute_reply.started": "2021-10-24T14:28:41.059285Z",
          "shell.execute_reply": "2021-10-24T14:28:41.410852Z"
        },
        "trusted": true,
        "id": "qw251Mq0C6qu"
      },
      "source": [
        "if u_out1_only:\n",
        "    targets = train[['pressure']].to_numpy().reshape(-1, 51)\n",
        "    train = train.drop(['pressure', 'id', 'breath_id','u_out'], axis=1)\n",
        "    test = test.drop(['id', 'breath_id','u_out'], axis=1)\n",
        "else:\n",
        "    targets = train[['pressure']].to_numpy().reshape(-1, 80)\n",
        "    train = train.drop(['pressure', 'id', 'breath_id'], axis=1)\n",
        "    test = test.drop(['id', 'breath_id'], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDN049pLEqUn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTqNgWdaC6qu"
      },
      "source": [
        "# 入力データのデータそのものの変形\n",
        "\n",
        "### RobustScalerについて\n",
        "入力データの分布に応じで変形。外れ値に強くしたり、正規分布に近くしたりできる。<br>\n",
        "https://helve-blog.com/posts/python/scikit-learn-feature-scaling/\n",
        "<br><br>\n",
        "### numpy bload cast error について\n",
        "原因は、trainとtestのデータの幅が違ったから。<br>\n",
        "RobustScalerのfitで値を変換するその内容を決定し、transformで値の変更を実施する。<br>\n",
        "そのため、fitしたときのcolumnの幅と、transformするときのcolumnの幅が揃わないとだめ。<br>\n",
        "https://www.headboost.jp/numpy-array-broadcasting/\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:28:41.412885Z",
          "iopub.execute_input": "2021-10-24T14:28:41.414300Z",
          "iopub.status.idle": "2021-10-24T14:28:44.429182Z",
          "shell.execute_reply.started": "2021-10-24T14:28:41.414259Z",
          "shell.execute_reply": "2021-10-24T14:28:44.428467Z"
        },
        "trusted": true,
        "id": "JmyEn8a4C6qu"
      },
      "source": [
        "#scaler = RobustScaler()\n",
        "scaler = StandardScaler()\n",
        "train = scaler.fit_transform(train)\n",
        "test = scaler.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSExUMQZC6qu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rww-whe3C6qu"
      },
      "source": [
        "# データ形状をTF向けに変更\n",
        "breath_idごとのデータになるように整形。<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:28:44.430582Z",
          "iopub.execute_input": "2021-10-24T14:28:44.430837Z",
          "iopub.status.idle": "2021-10-24T14:28:44.436511Z",
          "shell.execute_reply.started": "2021-10-24T14:28:44.430804Z",
          "shell.execute_reply": "2021-10-24T14:28:44.435526Z"
        },
        "trusted": true,
        "id": "rFcBC9M_C6qu"
      },
      "source": [
        "if u_out1_only:\n",
        "    train = train.reshape(-1, 51, train.shape[-1])\n",
        "    test = test.reshape(-1, 51, test.shape[-1])\n",
        "else:\n",
        "    train = train.reshape(-1, 80, train.shape[-1])\n",
        "    test = test.reshape(-1, 80, test.shape[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH8KVmATC6qu"
      },
      "source": [
        "# run tf function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:28:44.438194Z",
          "iopub.execute_input": "2021-10-24T14:28:44.438650Z",
          "iopub.status.idle": "2021-10-24T14:28:44.461574Z",
          "shell.execute_reply.started": "2021-10-24T14:28:44.438609Z",
          "shell.execute_reply": "2021-10-24T14:28:44.460922Z"
        },
        "trusted": true,
        "id": "pSG3nJ1oC6qv"
      },
      "source": [
        "def run_tf_blstm(epoch=int(50),batch_size=int(1024),train=None,test=None,targets=None):\n",
        "    \n",
        "    print(\"train.shape[-2:]:{}\".format(train.shape[-2:]))\n",
        "    print(\"train.shape  :{}\".format(train.shape))\n",
        "    print(\"targets.shape:{}\".format(targets.shape))\n",
        "        \n",
        "    #kf = KFold(n_splits=5, shuffle=True, random_state=2000)\n",
        "    kf = KFold(n_splits=5, shuffle=True)\n",
        "    test_preds = []\n",
        "    test_history = []\n",
        "    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n",
        "        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n",
        "\n",
        "        # TensorBoard setting\n",
        "        tensorboard_callback = tf.keras.callbacks.TensorBoard(\"{}-{}\".format(log_path, fold+1), histogram_freq=1)\n",
        "\n",
        "        X_train, X_valid = train[train_idx], train[test_idx]\n",
        "        y_train, y_valid = targets[train_idx], targets[test_idx]\n",
        "        model = keras.models.Sequential([\n",
        "            #keras.layers.Embedding(input_dim=train.shape[-2:], output_dim=300, mask_zero=True),\n",
        "            keras.layers.Input(shape=train.shape[-2:]),\n",
        "            keras.layers.Bidirectional(keras.layers.LSTM(300, return_sequences=True)),          \n",
        "            keras.layers.Bidirectional(keras.layers.LSTM(250, return_sequences=True)),\n",
        "            keras.layers.Bidirectional(keras.layers.LSTM(150, return_sequences=True)),\n",
        "            keras.layers.Bidirectional(keras.layers.LSTM(100, return_sequences=True)),\n",
        "            keras.layers.Dense(50, activation='selu'),\n",
        "            keras.layers.Dense(1),\n",
        "        ])\n",
        "        model.compile(optimizer=\"adam\", loss=\"mae\")    \n",
        "        \n",
        "        scheduler = ExponentialDecay(1e-3, 400*((len(train)*0.8)/batch_size), 1e-5)\n",
        "        lr = LearningRateScheduler(scheduler, verbose=1)\n",
        "\n",
        "        #es = EarlyStopping(monitor=\"val_loss\", patience=15, verbose=1, mode=\"min\", restore_best_weights=True)\n",
        "\n",
        "        history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=epoch, batch_size=batch_size, callbacks=[lr, tensorboard_callback])\n",
        "        test_history.append(history.history)\n",
        "        print(\"model_saveing.........\")\n",
        "        model.save('{}/model_save_fold{}'.format(log_path, fold+1))\n",
        "        #test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())\n",
        "\n",
        "        result = model.predict(test)\n",
        "        test_preds.append(result.squeeze())\n",
        "    \n",
        "    return test_preds, test_history\n",
        "\n",
        "def run_tf_lstm(epoch=int(50),batch_size=int(1024),train=None,test=None,targets=None):\n",
        "    #kf = KFold(n_splits=5, shuffle=True, random_state=2000)\n",
        "    kf = KFold(n_splits=5, shuffle=True)\n",
        "    test_preds = []\n",
        "    test_history = []\n",
        "    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n",
        "        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n",
        "        X_train, X_valid = train[train_idx], train[test_idx]\n",
        "        y_train, y_valid = targets[train_idx], targets[test_idx]\n",
        "        model = keras.models.Sequential([\n",
        "            #keras.layers.Embedding(input_dim=train.shape[-2:], output_dim=300, mask_zero=True),\n",
        "            keras.layers.Input(shape=train.shape[-2:]),\n",
        "            keras.layers.LSTM(300, return_sequences=True),\n",
        "            keras.layers.LSTM(250, return_sequences=True),\n",
        "            keras.layers.LSTM(150, return_sequences=True),\n",
        "            keras.layers.LSTM(100, return_sequences=True),\n",
        "            keras.layers.Dense(50, activation='selu'),\n",
        "            keras.layers.Dense(1),\n",
        "        ])\n",
        "        model.compile(optimizer=\"adam\", loss=\"mae\")    \n",
        "        \n",
        "        scheduler = ExponentialDecay(1e-3, 400*((len(train)*0.8)/batch_size), 1e-5)\n",
        "        lr = LearningRateScheduler(scheduler, verbose=1)\n",
        "\n",
        "        #es = EarlyStopping(monitor=\"val_loss\", patience=15, verbose=1, mode=\"min\", restore_best_weights=True)\n",
        "\n",
        "        history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=epoch, batch_size=batch_size, callbacks=[lr])\n",
        "        test_history.append(history.history)\n",
        "        print(\"model_saveing.........\")\n",
        "        model.save(f'model_save_fold{fold+1}')\n",
        "        result = model.predict(test)\n",
        "        #print(result.shape) #(50300, 80, 1)\n",
        "        #print(result.squeeze().shape)  #(50300, 80)\n",
        "        #print(result.squeeze().reshape(-1,1).shape) #(4024000, 1)\n",
        "        #test_preds.append(result.squeeze().reshape(-1, 1).squeeze())\n",
        "        test_preds.append(result.squeeze())\n",
        "    \n",
        "    return test_preds, test_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq96mqhdC6qv"
      },
      "source": [
        "# Train と Test\n",
        "\n",
        "## 戦略\n",
        "* full randamでロバスト性を狙う。外れ値は外したデータなので、randamで振られても安定するはず。\n",
        "* modelをsave。後で答えとどれだけずれているか見る。\n",
        "* <s>use only u_out = 1 data.</s>\n",
        "\n",
        "A.I<br>\n",
        "check "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ApEs-9g4_YX"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQYI1Qsu5rt3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:28:44.462683Z",
          "iopub.execute_input": "2021-10-24T14:28:44.463482Z",
          "iopub.status.idle": "2021-10-24T14:29:05.148562Z",
          "shell.execute_reply.started": "2021-10-24T14:28:44.463444Z",
          "shell.execute_reply": "2021-10-24T14:29:05.147248Z"
        },
        "trusted": true,
        "id": "YVY5FJoaC6qv"
      },
      "source": [
        "EPOCH = 20\n",
        "#EPOCH = 200\n",
        "#BATCH_SIZE = 2048\n",
        "BATCH_SIZE = 1024*2\n",
        "test_preds = list()\n",
        "\n",
        "device = tf_tpu_or_gpu_or_cpu()\n",
        "\n",
        "if use_trained_model:\n",
        "    pass\n",
        "else:\n",
        "    if device == \"cpu\" :\n",
        "        test_preds,history = run_tf_blstm(epoch=EPOCH,batch_size=BATCH_SIZE,train=train,test=test,targets=targets)\n",
        "\n",
        "    elif device == \"gpu\":\n",
        "        test_preds,history = run_tf_blstm(epoch=EPOCH,batch_size=BATCH_SIZE,train=train,test=test,targets=targets)\n",
        "    elif device == \"tpu\":\n",
        "        try:\n",
        "            with tpu_strategy.scope():\n",
        "                test_preds,history = run_tf_blstm(epoch=EPOCH,batch_size=BATCH_SIZE,train=train,test=test,targets=targets)\n",
        "        except :\n",
        "            print('Error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "99PxW4tlC6qv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oHY4j24C6qv"
      },
      "source": [
        "# re shape prediction results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:29:05.149575Z",
          "iopub.status.idle": "2021-10-24T14:29:05.150435Z",
          "shell.execute_reply.started": "2021-10-24T14:29:05.150191Z",
          "shell.execute_reply": "2021-10-24T14:29:05.150215Z"
        },
        "trusted": true,
        "id": "LevIy9GhC6qv"
      },
      "source": [
        "if use_trained_model:\n",
        "    pass\n",
        "else:\n",
        "    print(\"make pread......\")\n",
        "    preds = np.mean(test_preds, axis=0).tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:29:05.151491Z",
          "iopub.status.idle": "2021-10-24T14:29:05.152320Z",
          "shell.execute_reply.started": "2021-10-24T14:29:05.152057Z",
          "shell.execute_reply": "2021-10-24T14:29:05.152081Z"
        },
        "trusted": true,
        "id": "mMoboPEwC6qv"
      },
      "source": [
        "print(\"test_preds:{}\".format(len(test_preds)))\n",
        "print(\"test_preds[0]:{}\".format(test_preds[0].shape))\n",
        "\n",
        "print(\"preds:{}\".format(len(preds)))\n",
        "#print(\"test_preds:{}\".format(test_preds.shape))\n",
        "print(\"preds:{}\".format(len(preds[0])))\n",
        "\n",
        "preds_array = np.array(preds).reshape(-1)\n",
        "print(\"preds_array:{}\".format(preds_array.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-2JX8l3C6qw"
      },
      "source": [
        "# re read test.csv and add pred results to \"pressure\"\n",
        "\n",
        "In \"u_out1_only = False\" case, do not need to run following function.<br>\n",
        "Just only for \"u_out1_only = True\" case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:29:05.153389Z",
          "iopub.status.idle": "2021-10-24T14:29:05.154189Z",
          "shell.execute_reply.started": "2021-10-24T14:29:05.153910Z",
          "shell.execute_reply": "2021-10-24T14:29:05.153936Z"
        },
        "trusted": true,
        "id": "g30tK0zvC6qw"
      },
      "source": [
        "def add_pressure_data(df,preds):\n",
        "    index = 0\n",
        "    new_df = pd.DataFrame()\n",
        "    for k,grp in df.groupby(\"breath_id\"):\n",
        "        u_out_len = len(grp[grp[\"u_out\"] == 1])\n",
        "        if u_out_len < 52:\n",
        "            grp.loc[grp[\"u_out\"] == 1,\"pressure\"] = preds[index][:u_out_len]\n",
        "        else:\n",
        "            out_preds = preds[index]\n",
        "            for l in range(u_out_len - 51):\n",
        "                out_preds = out_preds.append(out_preds[-1])\n",
        "            grp.loc[grp[\"u_out\"] == 1,\"pressure\"] = out_preds\n",
        "        new_df = new_df.append(grp,ignore_index=True)\n",
        "        index += 1\n",
        "    return new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edy2-zD8C6qw"
      },
      "source": [
        "# In non debug mode, create submission data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:29:05.155375Z",
          "iopub.status.idle": "2021-10-24T14:29:05.156167Z",
          "shell.execute_reply.started": "2021-10-24T14:29:05.155898Z",
          "shell.execute_reply": "2021-10-24T14:29:05.155924Z"
        },
        "trusted": true,
        "id": "LGIwv2hoC6qw"
      },
      "source": [
        "if debug_mode:\n",
        "    pass\n",
        "else:\n",
        "    submission[\"pressure\"] = preds_array\n",
        "    submission.to_csv('submission_lstm.csv', index=False)\n",
        "    submission.to_csv('submission.csv', index=False)\n",
        "    print(\"make submission.csv........ ok\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:29:05.157326Z",
          "iopub.status.idle": "2021-10-24T14:29:05.158075Z",
          "shell.execute_reply.started": "2021-10-24T14:29:05.157832Z",
          "shell.execute_reply": "2021-10-24T14:29:05.157857Z"
        },
        "trusted": true,
        "id": "eHoRvWExC6qw"
      },
      "source": [
        " !zip -r file.zip 'submission_lstm.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:29:05.159255Z",
          "iopub.status.idle": "2021-10-24T14:29:05.160021Z",
          "shell.execute_reply.started": "2021-10-24T14:29:05.159775Z",
          "shell.execute_reply": "2021-10-24T14:29:05.159800Z"
        },
        "trusted": true,
        "id": "G7c3fSBsC6qw"
      },
      "source": [
        "from IPython.display import FileLink\n",
        "print(FileLink(r'submission_lstm.csv'))\n",
        "FileLink(r'submission_lstm.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAoPTVdkC6qx"
      },
      "source": [
        "# Load Pre Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:29:05.161152Z",
          "iopub.status.idle": "2021-10-24T14:29:05.161926Z",
          "shell.execute_reply.started": "2021-10-24T14:29:05.161671Z",
          "shell.execute_reply": "2021-10-24T14:29:05.161704Z"
        },
        "trusted": true,
        "id": "cpR12nXJC6qx"
      },
      "source": [
        "#if use_trained_model:\n",
        "if(0):\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/2021/100_GoogleBrain_VentilatorPressurePrediction/log/mylstm_v3.2_lite/model_save_fold2')\n",
        "    result = model.predict(train)\n",
        "    result = result.squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbeAqRrKC6qx"
      },
      "source": [
        "# Compare model result and train data, And visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-24T14:29:05.163098Z",
          "iopub.status.idle": "2021-10-24T14:29:05.164072Z",
          "shell.execute_reply.started": "2021-10-24T14:29:05.163807Z",
          "shell.execute_reply": "2021-10-24T14:29:05.163833Z"
        },
        "trusted": true,
        "id": "t4CRVl47C6qx"
      },
      "source": [
        "## res and tgt is numpy array\n",
        "def result_visual(result, targets, view_txt):\n",
        "  count_l = 0\n",
        "  count_s = 0\n",
        "  for res, tgt in zip(result,targets):\n",
        "      abs_diff =  np.sum(np.abs(res - tgt))\n",
        "      \n",
        "      if abs_diff > 500:\n",
        "          count_l += 1\n",
        "          if(count_l > 10):\n",
        "              continue\n",
        "\n",
        "          df = pd.DataFrame(res)\n",
        "          df = pd.concat([df, pd.DataFrame(tgt)], axis=1)\n",
        "          df.columns = [\"res\",\"tgt\"]\n",
        "          df[\"id\"] = df.index\n",
        "          df = pd.melt(df,id_vars=[\"id\"])\n",
        "          plt.figure()\n",
        "          fig = sns.lineplot(data=df, x='id', y=\"value\", hue=\"variable\")\n",
        "          fig.set_title(f\"{view_txt} >> ** abs_diff : {abs_diff}\")\n",
        "      elif abs_diff < 30:\n",
        "          count_s += 1\n",
        "          if(count_s > 10):\n",
        "              continue\n",
        "          df = pd.DataFrame(res)\n",
        "          df = pd.concat([df, pd.DataFrame(tgt)], axis=1)\n",
        "          df.columns = [\"res\",\"tgt\"]\n",
        "          df[\"id\"] = df.index\n",
        "          df = pd.melt(df,id_vars=[\"id\"])\n",
        "          plt.figure()\n",
        "          fig = sns.lineplot(data=df, x='id', y=\"value\", hue=\"variable\")\n",
        "          fig.set_title(f\"{view_txt} >> oo abs_diff : {abs_diff}\")\n",
        "\n",
        "def result_dict_visual(result_dict, targets, view_txt):\n",
        "  count_l = 0\n",
        "  count_s = 0\n",
        "  model_name_list = list(result_dict.keys())\n",
        "  #print(model_name_list)\n",
        "  #print(result_dict[model_name_list[0]].shape)\n",
        "  \n",
        "  for idx in tqdm(range(result_dict[model_name_list[0]].shape[0])):\n",
        "    \n",
        "    gt  = pd.DataFrame(targets[idx, :])\n",
        "    gt.columns = [\"gt\"]\n",
        "    gt[\"id\"] = gt.index\n",
        "\n",
        "    # OK\n",
        "    # メモリが解放される\n",
        "    plt.clf()\n",
        "    plt.close()\n",
        "\n",
        "    fig = plt.figure(figsize=(10.0, 10.0))\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    ax = sns.lineplot(data=gt, x='id', y='gt', ax=ax, label='gt')\n",
        "\n",
        "    abs_diff_list = []\n",
        "    for model_name in model_name_list:\n",
        "      pred = result_dict[model_name]\n",
        "      pred = pd.DataFrame(pred[idx, :])\n",
        "      pred.columns = [\"pred\"]\n",
        "      pred[\"id\"] = pred.index\n",
        "\n",
        "      _abs_diff =  np.sum(np.abs(gt['gt'].values - pred['pred'].values))\n",
        "      abs_diff_list.append(_abs_diff)\n",
        "      \n",
        "      abs_diff = np.mean(abs_diff_list)\n",
        "      # print(abs_diff)\n",
        "      \n",
        "      ax = sns.lineplot(data=pred, x='id', y='pred', ax=ax, label=model_name)\n",
        "\n",
        "    if(abs_diff < 30 or 500 < abs_diff):\n",
        "      ax.set_title(\">> ** abs_diff : {: 8.4f}\".format(abs_diff))\n",
        "      # print(\"fig saveing .............\")\n",
        "      plt.savefig('{}/pred_gt_diff{:08.4f}_idx{:06d}.png'.format(result_path, abs_diff, idx))\n",
        "\n",
        "    plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IalvVPR2zANX"
      },
      "source": [
        "#################################################\n",
        "# find model\n",
        "#\n",
        "save_model_list = glob.glob('{}/*model*'.format(log_path))\n",
        "pprint.pprint(save_model_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpitcfsmyqG7"
      },
      "source": [
        "#################################################\n",
        "# laod save model\n",
        "#\n",
        "result_dict = {}\n",
        "for model_path in save_model_list:\n",
        "  model_name = model_path.split('/')[-1]\n",
        "  print(\">>>>>>>> {} >>>>>>>>>>>\".format(model_name))\n",
        "  model = tf.keras.models.load_model(model_path)\n",
        "  _result = model.predict(train)\n",
        "  _result = _result.squeeze()\n",
        "  result_dict[model_name] = _result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VidjgSzyke9"
      },
      "source": [
        "#################################################\n",
        "# visual model result\n",
        "#\n",
        "#result_dict_visual(result_dict, targets, model_name)\n",
        "result_dict_visual(result_dict, targets, model_name)\n",
        "\n",
        "\n",
        "#for model_name, result in result_dict.items():\n",
        "#  print(\">>>>>>>> {} >>>>>>>>>>>\".format(model_name))\n",
        "#  #result_visual(result, targets, model_name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hafhcmH5C6qx"
      },
      "source": [
        "# "
      ]
    }
  ]
}